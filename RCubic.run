#!/usr/bin/env python
#camelCase tab indented, if unsure, read pep8 thanks
# vim: ts=4 noet filetype=python

#TODO
# * in session mode append random string to dir name
# Fix fileMode config to not use gitRepo as path and rename vars

from __future__ import print_function

import sys
import os
import re
import errno
import fcntl
import subprocess
import time
import argparse
import threading
import random
import signal
import sqlite3
import os.path
import smtplib
import collections
import logging
import fnmatch
import uuid
import shutil
import simplejson

from email.mime.text import MIMEText
#######
from RCubic.RESTCommunicator import RESTCommunicator
from RCubic.ResourceScheduler import ResourceScheduler
from RCubic.ReleaseScript import Status, ReleaseScriptManager, ReleaseScript
from RCubic.RCubicUtilities import log, popenNonblock, ConfigurationError, FatalRuntimeError, LogToDB
#######

#third party libraries:
from daemon import Daemon
from lxml import etree
import gevent
from gevent import (event, server, socket)

class RcubicNotification(object):
	def __init__(self):
		self.email = {}
		self.enabled = True
		self.emailFrom = 'RcubicNotify@example.com'
		self.subject = "Rcubic:"
		self.server = "localhost"
		self.queue = collections.deque()
		self.cc = ""

	def disable(self):
		if self.enabled == True:
			log("Notifications have been disabled.", logging.DEBUG)
		self.enabled = False

	def addProductEmail(self, product, email):
		self.email[product.lower()] = email

	def isProductConfigured(self, product):
		return product in self.email

	def notifyProduct(self, products, subject, message):
		if self.enabled:
			self.queue.append((products, subject, message))

	def _processMessage(self, products, subject, message):
		msg = MIMEText(message)
		recipients = [self.email[prod] for prod in products]
		recipients.append(self.cc)
		msg['Subject'] = "%s %s %s" %(self.subject, ", ".join(products), subject)
		msg['From'] = self.emailFrom
		msg['To'] = ', '.join(recipients)
		smtp = smtplib.SMTP(self.server)
		smtp.sendmail(self.emailFrom, recipients, msg.as_string())
		smtp.quit()

	def processQueue(self):
		try:
			while True:
				self._processMessage(*self.queue.popleft())
		except IndexError:
			#queue is empty
			pass

class Rcubic(object):
	def __init__(self, opts):
		#Please don't abuse Rcubic.opts thanks!
		self.opts = opts
		self.toInstall = []
		self.log = None
		self.config = {}
		self.port = 0
		self.notification = RcubicNotification()
		self.rsm = ReleaseScriptManager(self)
		self.aisDir = ""
		self.aisOverrideDir = ""
		self.aisFilter = dict()
		self.gitDir = ""
		self.groupSelect = []
		self.signalEvent = gevent.event.Event()
		self.abortSent = False
		self.environment = ""
		self.resources = { }
		# dot's html map output is: "x,y x,y x,y"
		# but it should be: "x,y,x,y,x,y"
		# this is a regex to fix that
		self.fixCoord = re.compile(' (?=[\d]*,[\d]*)')
		self.gitHead = ""
		#Special groups are always selected, even if not passed through -g however they are not counted toward number of groups to install
		#self.config["specialGroups"] = ["release"] #Now self.config["specialGroups"]
		baseConfigReq = [ "basePath", "hostListLocation", "gitRepo", "fileMode", "gerritURL", "gerritProject", "basePathWeb",
						  "environmentOptions", "specialGroups", "specialJobs",
						  "listenAddress", "listenPortRange", "jobExpireTime",
						  "smtpServer", "emailSubjectPrefix", "emailFrom", "maxEmailLogSizeKB",
						  "defaultRelease", "hijackPoint", "SSLKey", "SSLCert", "token"]
		splitOptions = ["specialGroups", "specialJobs"]

		#calculate path to xml relative to rcubic python, this will make symlinking tricky
		if(self.opts.conf == None):
			xmlpath = "%s/rcubic.xml" % sys.argv[0][0:sys.argv[0].rindex("/")]
		else:
			xmlpath = self.opts.conf

		self._readConfig(xmlpath, baseConfigReq)
		self.resourceScheduler = ResourceScheduler(self.resources)
		self.config["gitRepo"] = [self.config["gitRepo"]]

		self._initPaths()
		self._initGit()
		self._readConfig("%s/config.xml" %(self.releaseDir), splitOptions=splitOptions)

		self.rsm.specialJobs = self.config["specialJobs"]

		self._initNotification()

		if self.opts.sessionMode:
			self.log = LogToDB(":memory:")
		else:
			self.log = LogToDB(self.config["auditLog"])

		try:
			self._validate()
		except:
			self.cleanup()
			raise

		if self.opts.validate:
			self.cleanup()

	def _validate(self):
		if self._readNotificationConfig() <= 0:
			raise ConfigurationError("No notification configured. This is a bad thing")

		#TODO validate aisOverrideDir and aisDir (do they exist?)
		self._selectWhatToInstall()

		if self.rsm.countGroups(self.config["specialGroups"]) <= 0:
			raise ConfigurationError("ERROR: nothing to install")

		if not self._verifyBasePath():
			raise ConfigurationError("ERROR: basePath missmatch")

		self.rsm.expandglobs()
		self.rsm.convertcdep()
		self.rsm.inferParents()
		self.rsm.gparentCompile()

		if self.opts.environment:
			self.environment = self.opts.environment
		elif "environment" in self.config:
			self.environment = self.config["environment"]
		else:
			raise ConfigurationError("Environment not not specified.")

		self._updateGraph(updateDot=True)

		valid = self.validate()
		if valid != True:
			log("Validation failure:\n%s" %(valid), logging.ERROR)
			raise ConfigurationError("Encountered Validation error. See above for cause of failure.")

		if self.environment not in self.config["environmentOptions"]:
			log("environmentOptions: %s" %self.config["environmentOptions"], logging.ERROR)
			raise ConfigurationError("Invalid environment specified")

		if not self._verifyNotificationGroups():
			raise ConfigurationError("No notification configured. This is a bad thing")

	def _initNotification(self):
		self.notification.emailForm = self.config["emailFrom"]
		self.notification.subject = self.config["emailSubjectPrefix"]
		self.notification.server = self.config["smtpServer"]
		self.notification.cc = self.config.get("cc", "")
		if self.opts.foreground:
			self.notification.disable()
		if self.config.get("notification", "True") == "False":
			self.notification.disable()

	def _initGit(self):
		if not self.config["fileMode"]:
			if self.opts.refspec:
				self.config["gitBranch"] = "FETCH_HEAD"
			elif self.opts.branch:
				self.config["gitBranch"] = self.opts.branch
			elif "gitBranch" not in self.config:
				self.config["gitBranch"] = "master"

			try:
				os.makedirs(self.gitDir)
			except OSError:
				pass
		
			try:
				os.makedirs("%s/work/log" % (self.config["basePath"]))
			except OSError:
				pass

			if not os.access(self.gitDir, os.W_OK):
				raise FatalRuntimeError("ERROR: '%s' does not have write access." %self.gitDir)

			with open("/dev/null", "w") as devnull:
				if subprocess.call(["git","rev-parse","--is-inside-work-tree"], cwd=self.gitDir, stdout=devnull, stderr=devnull) == 0:
					#Repo already exists we just need to updated
					if self.opts.sessionMode:
						raise FatalRuntimeError("'%s' already exists. This should be impossible." %(self.gitDir))
				else:
					try:
						#repo does not exist and needs to be clone
						if subprocess.call(['git', 'clone', self.config["gitRepo"][0], "%s" %(self.gitDir)]) != 0:
							raise FatalRuntimeError("git clone failed")
					except:
						raise FatalRuntimeError("Cannot clone into directory. Is it not empty?")

				#this is a safety to roll back any changes someone's made.
				subprocess.call(['git', 'reset', '--hard'], cwd=self.gitDir)

				#Lets fetch remote
				fetchCommand = ['git', 'fetch', self.config["gitRepo"][0]]
				if self.opts.refspec:
					fetchCommand.append(self.opts.refspec)
				if subprocess.call(fetchCommand, cwd=self.gitDir) != 0:
					raise FatalRuntimeError("git fetch failed")

				#checkout the target of which we work
				if subprocess.call(['git', 'checkout', "remotes/origin/%s" % self.config['gitBranch']], cwd=self.gitDir) != 0:
					raise FatalRuntimeError("git checkout failed 1")

				processResult = popenNonblock(["git", "rev-parse","HEAD"], cwd=self.gitDir)
				if(processResult[0] != 0):
					raise FatalRuntimeError("git head hash get failed")
				self.gitHead = processResult[1].rstrip()

				#subprocess.call(['git', 'log', '-1', '--format="%H"'], cwd=self.gitDir, stdout=githash) #todo:save hash
			log("Git repo has been updated")
			return True
		else:
			# Copy the directory
			try:
				shutil.copytree(self.config["gitRepo"][0], self.gitDir)
			except:
				pass

			try:
				os.makedirs("%s/work/log" % (self.config["basePath"]))
			except OSError:
				pass

			if not os.access(self.gitDir, os.W_OK):
				raise FatalRuntimeError("ERROR: '%s' does not have write access." %self.gitDir)


	def _flattenOption(self, inList):
		outList = []
		s = re.compile("[;,\s]+")
		for subList in inList:
			outList.extend(s.split(subList))
		return outList

	def _populateAISFilter(self):
		self.aisFilter = dict()

		if self.opts.ais and self.opts.skipAis:
			log("conflicting options selected skip and select ais. Will honnor only select.")

		if self.opts.ais:
			self.aisFilter["positiveFilter"] = True
			self.aisFilter["files"] = self._flattenOption(self.opts.ais)
			self.aisFilter["files"].extend(self.config["specialJobs"])
		elif self.opts.skipAis:
			self.aisFilter["positiveFilter"] = False
			self.aisFilter["files"] = self._flattenOption(self.opts.skipAis)

	def _aisHijack(self):
		for rs in self.rsm:
			if rs.group not in self.config["specialGroups"]:
				rs.hijack(self.config["hijackPoint"])

	def _selectGroups(self):
		if self.opts.group is not None:
			self.groupSelect = self._flattenOption(self.opts.group)
			self.groupSelect.extend(self.config["specialGroups"])

	def _initPaths(self):
		self.originalBasePath = self.config["basePath"]
		if(self.config["basePathWeb"] != ""):
			bpw = "/" + self.config["basePathWeb"]
		else:
			bpw = ""
		self.config["basePath"] = "%s%s" % (self.config["basePath"], bpw)
		self.config["archivePath"] = "%s/archive/" % (self.config["basePath"])
		if self.opts.sessionMode:
			if self.groupSelect != []:
				groupDirString = self.groupSelect[0] #TODO properly implement 'group'.
			else:
				groupDirString = "all"
			self.config["basePath"] = "%s/%s_%s" %(self.config["basePath"], uuid.uuid1(), groupDirString)

		self.gitDir = "%s/work/git" %self.config["basePath"]
		if self.opts.release:
			self.config["defaultRelease"] = self.opts.release
		self.releaseDir = "%s/%s" %(self.gitDir, self.config["defaultRelease"])
		self.aisOverrideDir = "%s/override" %(self.releaseDir)
		self.aisDir = "%s/release" %(self.gitDir)
		self.validationDir = "%s/validation" %(self.gitDir)

		if "baseURL" in self.config:
			#self.fullURL = "%s/%s/work" %(self.config["baseURL"], self.config["basePath"][len(self.originalBasePath):])
			tURL = self.config["basePath"][len(self.originalBasePath):]
			if(len(tURL) > 0):
				tURL = tURL + '/'
			self.fullURL = "%s/%s?prefix=%swork" %(self.config["baseURL"], self.config["basePathWeb"], tURL)
			self.baseURL = "%s/%s" %(self.config["baseURL"], self.config["basePath"][len(self.originalBasePath):])
		log("URL: %s" % self.fullURL, logging.INFO)

		fileMap = { "fdotFile":"full.dot", "fpngFile":"full.png", "adotFile":"arb.dot",
					"asvgFile":"arb.svg", "pidFile":"rcubic.pid", "logFile":"rcubic.log",
					"auditLog":"rcubic.aud" , "njsonFile": "nodes.json"}
		for k, v in fileMap.iteritems():
			self.config[k] = "%s/work/%s" %(self.config["basePath"], v)


	def _readConfig(self, configFile, mustHaveConfigOptions=None, splitOptions=None):
		if mustHaveConfigOptions is None:
			mustHaveConfigOptions = []
		if splitOptions is None:
			splitOptions = []

		try:
			self.etree = etree.parse(configFile)
		except IOError:
			raise ConfigurationError("ERROR: Could not open configuration file (%s)." %(configFile))
		except etree.XMLSyntaxError as error:
			raise ConfigurationError("ERROR: failed to parse config file (%s): %s" %(configFile, error))

		#TODO save config to local var and then copy values after tweaking
		#TODO narrow /*/ to /rcubic after full rename
		for element in self.etree.xpath("/*/config/option"):
			try:
				if element.attrib["name"] == "basePath" and "basePath" in self.config:
					raise ConfigurationError("ERROR: basePath is being overriden in %s." %(configFile))
				elif element.attrib["name"] in splitOptions:
					self.config[element.attrib["name"]] = element.attrib["value"].split()
				else:
					self.config[element.attrib["name"]] = element.attrib["value"]
			except KeyError:
				self.config = {}
				raise ConfigurationError("ERROR: Element on line %i of %s is missing an attribute." %(element.sourceline, element.base))

		# Go through resources limit config
		for element in self.etree.xpath("/*/resources/option"):
			try:
				resource = element.attrib["name"]
				value = int(element.attrib["value"])
				if value == -1:
					value = float('inf')
				self.resources[resource] = value
			except ValueError:
				raise ConfigurationError("ERROR: Resource on line %i of %s if not an int." % (element.sourceline, element.base))
			except:
				raise ConfigurationError("ERROR: Resource on line %i of %s is malformed." % (element.sourceline, element.base))

		for mhco in mustHaveConfigOptions:
			if mhco not in self.config:
				raise ConfigurationError("ERROR: %s is not defined in config file (%s)" %(mhco, configFile))

		#value validation does not belong in this function
		if "listenPortRange" in self.config and "listenPortRange" in mustHaveConfigOptions:
			listenPorts=[]
			try:
				for port in self.config["listenPortRange"].split('-'):
					listenPorts.append(int(port.strip()))
				if len(listenPorts) != 2:
					raise ValueError
				self.config["listenPortRange"] = ( listenPorts[0], listenPorts[1] )
			except ValueError:
				raise ConfigurationError("ERROR: port range specification error: %s" %(self.config["listenPortRange"]))

		#value validation does not belong in this function
		if "jobExpireTime" in self.config and "jobExpireTime" in mustHaveConfigOptions:
			try:
				self.config["jobExpireTime"] = int(self.config["jobExpireTime"])
			except ValueError:
				raise ConfigurationError("ERROR: jobExpireTime validation failure")

		# String to bool
		if "fileMode" in mustHaveConfigOptions:
			if self.config["fileMode"].lower() == "true":
				self.config["fileMode"] = True
			elif self.config["fileMode"].lower() == "false":
				self.config["fileMode"] = False
			else:
				raise ConfigurationError("ERROR: fileMode validation failure: expected True/False")

		return True

	def _selectWhatToInstall(self):
		self._selectGroups()
		self._populateAISFilter()
		toInstallGroups=[]

		for element in self.etree.xpath("/*/release/install"):
			try:
				version = element.attrib["version"]
				group = element.attrib["group"]
			except KeyError:
				raise ConfigurationError("Element on line %i of %s is missing an attribute." %(element.sourceline, element.base))

			phase = ReleaseScript.Phase.DEFAULT
			if "phase" in element.attrib:
				phase = element.attrib["phase"].upper()
				if not phase in ReleaseScript.Phase.all:
					raise ConfigurationError("Attribute phase on line %i of %s has unrecognized value: '%s'." %(element.sourceline, element.base, phase))

			try:
				fullOverride = element.attrib["fullOverride"]
				if fullOverride.lower() == "true":
					fullOverride = True
				elif fullOverride.lower() == "false":
					fullOverride = False
				else:
					raise ConfigurationError("Element fullOverride is not (True|False) on line %i of %s." %(element.sourceline, element.base))
			except KeyError:
				fullOverride = False

			toInstall = False
			if group in self.config["specialGroups"]:
				toInstall = True
			if self.groupSelect:
				if group in self.groupSelect:
					toInstall = True
			else:
				if self.log.isNewestVersion(group, version):
					toInstall = True
				else:
					log("Skipping %s a version greater than or equal %s is installed." %(group, version))

			installed = 0
			if toInstall:
				toInstallGroups.append(group)
				if not fullOverride:
					installed += self.rsm.addGroup(self.aisDir, group, version, phase, self.aisFilter)
				installed += self.rsm.addGroup(self.aisOverrideDir, group, version, phase, self.aisFilter)
				if installed <= 0:
					raise ConfigurationError("No matching install scripts found for group: %s." %(group))

		log("Installing groups %s." % " ".join(sorted(toInstallGroups)), logging.INFO)

		if self.aisFilter:
			self._aisHijack()

		return True

	def _readNotificationConfig(self):
		count = 0
		for product in self.etree.xpath("/*/notification/product"):
			try:
				self.notification.addProductEmail(product.attrib["name"], product.attrib["email"])
			except KeyError:
				log("Element on line %i of %s is missing an attribute." %(product.sourceline, product.base), logging.ERROR)
				return 0
			count += 1
		return count

	def _verifyNotificationGroups(self):
		exit = True
		for rs in self.rsm:
			for product in rs.products:
				if not self.notification.isProductConfigured(product):
					exit = False
					log("'%s' references notification group '%s' which is not defined" %(rs.script, product), logging.ERROR)
		return exit

	def _verifyBasePath(self):
		for rs in self.rsm:
			if not rs.script.startswith(self.config["basePath"]):
				return False
		return True

	def reschedule(self, scriptName):
		response = self.rsm.find(scriptName)
		if not response:
			print("TODO")
			return False
		gevent.spawn(response.queue)
		return True

	def manualOverride(self, scriptName):
		response = self.rsm.find(scriptName)
		if not response:
			print("No such script")
			return False
		response.status = Status.MANUALOVERRIDE
		self.refreshStatus(response)
		response.event.set()
		return True

	def validate(self):
		errorMessages = ""

		#Validate and run validation scripts
		if self.opts.strictValidation:
			if os.path.exists(self.validationDir):
				arguments = [ self.environment, self.opts.release, " ".join(self.rsm.groups) ]
				prependRe = re.compile("^", re.M)
				for validationScript in os.listdir(self.validationDir):
					validationScript = "%s/%s" %(self.validationDir, validationScript)
					if not os.access(validationScript, os.X_OK):
						errorMessages += "\tValidation script %s is not executable\n" % (validationScript)
						continue
					with open("/dev/null", "w") as devnull:
						process = subprocess.Popen(["bash", "-n", validationScript], stdout=devnull, stderr=devnull)
					if process.wait() != 0:
						errorMessages += "\tValidation script %s is not valid bash\n" % (validationScript)
						continue
					vsl = [validationScript]
					vsl.extend(arguments)
					process = subprocess.Popen(vsl, cwd = self.releaseDir, stdout = subprocess.PIPE, stderr = subprocess.PIPE )
					if process.wait() != 0:
						stdout, stderr = process.communicate()
						if stdout or stdout:
							errorMessages += "\tValidation script %s failed:\n" % (validationScript)
						if stdout:
							errorMessages += "\t\tstdout:\n"
							errorMessages += prependRe.sub("\t\t\t", stdout.strip(), 0)
							errorMessages += "\n"
						if stderr:
							errorMessages += "\t\tstderr:\n"
							errorMessages += prependRe.sub("\t\t\t", stderr.strip(), 0)
							errorMessages += "\n"

		rsmErrorMessages = self.rsm.validate()
		if rsmErrorMessages != True:
			errorMessages += rsmErrorMessages

		if errorMessages == "":
			return True
		else:
			return errorMessages

	def _updateGraph(self, updateDot=False):
		log("Update graph called", logging.DEBUG)
		try:
			meta = [
					#fullpng takes too long to render
					#(self.config["fdotFile"], self.config["fpngFile"], self.config["fhtmlFile"], False),
					(self.config["adotFile"], self.config["asvgFile"], self.config["njsonFile"], True)
				   ]
			for df, sf, jn, t in meta:
				if updateDot:
					with open(df, "w") as dotFD:
						dotFD.write(self.rsm.toDot(self.baseURL, len(self.gitDir), t))
					with open(sf, "w") as svgFD:
						processResult = popenNonblock(["dot", "-Tsvg", df])
						# Regex fix the coordinate space comma issue (look at fixCoord definition)
						svgFD.write(self.fixCoord.sub(',', processResult[1]))
					if processResult[0] != 0:
						return False
				with open(jn, "w") as jsonFD:
					jsonFD.write(self.rsm.toJSON())

			return True
		except OSError:
			raise FatalRuntimeError("ERROR: graphviz not installed.")
			return False

	def _updateProgress(self, scriptName, version, kind, message):
		rs = self.rsm.find(scriptName)
		if not rs:
			log("received message with unmatched script. (%s, %s)" %(scriptName, version), logging.ERROR)
			return False
		if rs.version != version:
			log("received message with unmatched version. (%s, %s)" %(scriptName, version), logging.ERROR)
			return False
		if kind == "PROGRESS":
			if not rs.updateProgress(message):
				log("received message with invalid progress message. (%s, %s, %s)" %(scriptName, version, message), logging.ERROR)
				return False
			self.signalEvent.set()
		else:
			log("received message with unknown message type (%s)." %(kind), logging.ERROR)
			return False
		return True

	def refreshStatus(self, rs):
		self.signalEvent.set()

		self.log.saveStatus(rs.group, rs.version, rs.status, self.gitHead, rs.name)
		if rs.isDone() and self.rsm.isGroupSuccess(rs.group):
			self.log.saveStatus(rs.group, rs.version, rs.status, self.gitHead)
			pass

		if self.opts.sessionMode and rs.isFailed:
			self.abort()

		if rs.isFailed:
			# Get last 'maxEmailLogSizeKB' kilobytes of log for email.
			try:
				logFile=open("%s/work/log/%s.log" %((self.manager.rcubic.config["basePath"], self.name)), 'r')
				logFile.seek(0,2)
				logSize = logFile.tell()
				logFile.seek(max(-1024 * self.config['maxEmailLogSizeKB'], -logSize), 2)
				logContent = logFile.read()
			except:
				logContent="ERROR opening log file!"
			self.notification.notifyProduct(rs.products, "%s (%s) failed" %(rs.name, rs.version), logContent)
		elif rs.hasFailed and rs.isSuccess():
			self.notification.notifyProduct(rs.products, "%s (%s) recovered" %(rs.name, rs.version), "The script %s which has previously failed has now succeeded." % rs.name)

	def abort(self, signum=None, frame=None):
		#TODO: remove this and just call the RSM one
		#signum and frame are needed as they are passed up from threading class.
		if self.abortSent:
			log("Abort already sent to all jobs.", logging.ERROR)
			log("jobs: %s" % self.rsm, logging.DEBUG)
			return
		else:
			self.abortSent = True

		log("Aborting all jobs. Please be patient.", logging.INFO)
		self.rsm.abortJobs()

	def processEvents(self):
		#We sleep here to give socket server some time to init
		gevent.sleep(1)

		expireTime = time.time() + 3600 * self.config["jobExpireTime"]
		while self.communicator.started():
				self.signalEvent.wait(10.0)
				if self.signalEvent.is_set():
					self.signalEvent.clear()
					self._updateGraph()
					self.notification.processQueue()
				if self.opts.foreground:
					if self.rsm.isDone():
						break
				else:
					if self.rsm.isSuccess():
						break
				if time.time() > expireTime:
					log("Tired of waiting for jobs to exit. Aborting.", logging.ERROR)
					self.abort()
					break
		self.communicator.stop()
	
	def cleanup(self):
		try:
			if(not self.opts.sessionMode):
				uid = uuid.uuid1()
				uDir = "%s/%s" % (self.config["archivePath"], uid)
				os.makedirs(uDir)
				files = [ self.config['adotFile'], self.config['asvgFile'], self.config['njsonFile'] ]
				if not self.opts.foreground and not self.opts.validate:
					files.append(self.config['logFile'])
				for f in files:
					shutil.copy(f, uDir)
				if(not self.opts.validate):
					shutil.copytree("%s/%s" % (self.config["basePath"], "work/log"), "%s/%s" % (uDir,"log"))
				log("Copied files to: %s" % (uDir), logging.INFO)

				tURL = "archive/%s" % uid
				if(len(tURL) > 0):
					tURL = tURL + '/'
				if(self.config["basePathWeb"] != ""):
					bpw = "/" + self.config["basePathWeb"]
				else:
					bpw = self.config["basePathWeb"]
				fullURL = "%s%s/?prefix=%s" %(self.config["baseURL"], bpw, tURL)
				log("Job archive available at: %s" % (fullURL), logging.INFO)
		except:
			log("Something went wrong while trying to copy files to archive: %s" % (str(sys.exc_info())), logging.ERROR)

		if not self.opts.cleanup and self.opts.sessionMode:
			try:
				shutil.rmtree("%s/%s" % (self.config["basePath"], "work/git"))
				log("Removed git directory from session folder.", logging.INFO)
			except:
				log("Something went wrong when trying to remove git directory from session folder: %s" % (str(sys.exc_info())), logging.ERROR)

		elif self.opts.cleanup and self.opts.sessionMode:
			try:
				shutil.rmtree(self.config["basePath"], False)
				log("Removed session folder.", logging.INFO)
			except KeyError:
				#assume base path is not configured.. which means we didn't write anything to it either
				pass

	def run(self):
		time.sleep(1) #Sleep to let stdout get re-assigned on daemonization fork

		#TODO: this is a hack
		if self.opts.sessionMode:
			self.log = LogToDB(":memory:")
		else:
			self.log = LogToDB(self.config["auditLog"])

		self._updateGraph()
		if self.config["SSLKey"] == "" or self.config["SSLCert"] == "":
			self.config["SSLKey"] = None
			self.config["SSLCert"] = None
		if self.config["token"] == "":
			self.config["token"] = None
		
		self.communicator = RESTCommunicator(self, bind=self.config["listenAddress"], portRange=self.config["listenPortRange"], SSLKey=self.config["SSLKey"], SSLCert=self.config["SSLCert"], token=self.config["token"])
		rse = self.rsm.queueJobs() #release script event

		jobs = [gevent.spawn(rsei) for rsei in rse]
		jobs.extend([gevent.spawn(self.communicator.start,block=False), gevent.spawn(self.processEvents)])
		# Starts non-blocking so we can get port
		self.communicator.start(block=False)
		log("Server started at %s:%s" % (self.communicator.bind, self.communicator.port), logging.INFO)
		self.token = self.communicator.token
		self.port = self.communicator.port
		gevent.joinall(jobs)
		time.sleep(5)
		self._updateGraph(updateDot=True)
		self.notification.processQueue()

		self.cleanup()

		if not self.rsm.isDone():
			log("exited with orphaned jobs", logging.ERROR)
			return False
		return self.rsm.isSuccess()

class RcubicDaemon(Daemon):
	def setRcubic(self,rcubic):
		self.rcubic = rcubic
	def run(self):
		self.rcubic.run()

def _setupLogging():
	dpp12_time = '%Y-%m-%d %H:%M:%S' + str.format('{0:+06.2f}', float(time.altzone) / 3600).replace(".", "")
	log_format = logging.Formatter('[%(asctime)s] | %(filename)s | %(process)d | %(levelname)s | %(message)s', datefmt=dpp12_time)
	handler = logging.StreamHandler()
	handler.setFormatter(log_format)
	logger = logging.getLogger('')
	logger.setLevel(logging.INFO)
	#logger.setLevel(logging.DEBUG)
	logger.addHandler(handler)

if __name__ == "__main__":
	_setupLogging()
	argParser = argparse.ArgumentParser(description='Rcubic does stuff! Important stuff!')
	#argParser.add_argument('-p', dest='path', metavar='path', required=True, help='Base path of release.')
	argParser.add_argument('-e', dest='environment', metavar='environmet', required=False, help='Environment options.')
	argParser.add_argument('-r', dest='release', metavar='release_directory', required=False, help='Release. Number.')
	argParser.add_argument('-g', dest='group', metavar='group', action='append',
							help='Select Group to run. Can be specified multiple times for multiple groups.')
	argParser.add_argument('-v', dest='validate', action='store_const', const=True, default=False, help='Validate configuration.')
	argParser.add_argument('-f', dest='foreground', action='store_const', const=True, default=False,  help='Run in foreground (debug) mode.')
	argParser.add_argument('-s', dest='sessionMode', action='store_const', const=True, default=False,  help='Run in Session mode.')
	argParser.add_argument('-C', dest='cleanup', action='store_const', const=False, default=True, help='When in session mode, upon completion do not clean up work directory.')
	argParser.add_argument('-a', dest='ais', metavar='ais_list', action='append', default=None,
							help='Select a single AIS to run. Can be specified multiple times for multiple AIS. Do not use with -i.')
	argParser.add_argument('-A', dest='skipAis', metavar='ais_list', action='append', default=None,
							help='Select an AIS to skip. Can be specified multiple times for multiple AIS. Do not use with -a.')
	argParser.add_argument('--strictValidation', dest='strictValidation', action='store_const', const=True, default=False, help='Strict validation configuration. Run validation scripts.')
	argParser.add_argument('--refspec', dest='refspec', metavar='refspec', default=None,  help='refspec to fetch from, sets branch to FETCH_HEAD.')
	argParser.add_argument('-b', dest='branch', metavar='branch', default=None, help='branch to checkout defaults to master unless --refspec is specified')
	argParser.add_argument('--conf', dest='conf', default=None, help='path to rcubic.xml config file. Default RCubic.run directory')
	opts = argParser.parse_args()

	try:
		rcubic = Rcubic(opts)
	except ConfigurationError as ce:
		log(ce, logging.ERROR)
		log("Encountered configuration error. See above for cause of failure.", logging.ERROR)
		sys.exit(2)

	if opts.validate:
		log("Passed Validation!", logging.INFO) #This won't be reached if errors are found.
		sys.exit(0)

	signal.signal(signal.SIGTERM, rcubic.abort)
	signal.signal(signal.SIGINT, rcubic.abort)

	if opts.foreground:
		if rcubic.run():
			sys.exit(0)
		else:
			sys.exit(1)
	else:
		rcubicd = RcubicDaemon(rcubic.config["pidFile"], stdout=rcubic.config["logFile"], stderr=rcubic.config["logFile"])
		rcubicd.setRcubic(rcubic)
		rcubicd.start()
