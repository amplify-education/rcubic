#!/usr/bin/env python
# vim: ts=4 noet filetype=python

# This file is part of RCubic
#
#Copyright (c) 2012 Wireless Generation, Inc.
#
#Permission is hereby granted, free of charge, to any person obtaining a copy
#of this software and associated documentation files (the "Software"), to deal
#in the Software without restriction, including without limitation the rights
#to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
#copies of the Software, and to permit persons to whom the Software is
#furnished to do so, subject to the following conditions:
#
#The above copyright notice and this permission notice shall be included in
#all copies or substantial portions of the Software.
#
#THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
#IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
#FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
#AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
#LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
#OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
#THE SOFTWARE.


#camelCase tab indented, if unsure, read pep8 thanks

#TODO
# * in session mode append random string to dir name
# Fix fileMode config to not use gitRepo as path and rename vars

from __future__ import print_function

import sys
import os
import re
import errno
import fcntl
import subprocess
import time
import argparse
import threading
import random
import signal
import sqlite3
import os.path
import smtplib
import collections
import logging
import fnmatch
import uuid
import shutil
import simplejson

from email.mime.text import MIMEText
#######
from RCubic.RESTCommunicator import RESTCommunicator
from RCubic.ResourceScheduler import ResourceScheduler
from RCubic.ReleaseScript import Status, ReleaseScriptManager, ReleaseScript
from RCubic.RCubicUtilities import popenNonblock, ConfigurationError, FatalRuntimeError, LogToDB
from RCubic.daemon import Daemon
#######

#third party libraries:
from lxml import etree
import gevent
from gevent import (event, server, socket)

class RcubicNotification(object):
	def __init__(self):
		self.email = {}
		self.enabled = True
		self.emailFrom = 'RcubicNotify@example.com'
		self.subject = "Rcubic:"
		self.server = "localhost"
		self.queue = collections.deque()
		self.cc = ""

	def disable(self):
		if self.enabled == True:
			logging.debug("Notifications have been disabled.")
		self.enabled = False

	def addProductEmail(self, product, email):
		self.email[product.lower()] = email

	def isProductConfigured(self, product):
		return product in self.email

	def notifyProduct(self, products, subject, message):
		if self.enabled:
			self.queue.append((products, subject, message))

	def _processMessage(self, products, subject, message):
		msg = MIMEText(message)
		recipients = [self.email[prod] for prod in products]
		recipients.append(self.cc)
		msg['Subject'] = "%s %s %s" %(self.subject, ", ".join(products), subject)
		msg['From'] = self.emailFrom
		msg['To'] = ', '.join(recipients)
		try:
			smtp = smtplib.SMTP(self.server)
			smtp.sendmail(self.emailFrom, recipients, msg.as_string())
			smtp.quit()
		except:
			logging.error("Sending email failed! Message: %s" % msg)

	def processQueue(self):
		try:
			while True:
				self._processMessage(*self.queue.popleft())
		except IndexError:
			#queue is empty
			pass

class Rcubic(object):
	def __init__(self, opts):
		#Please don't abuse Rcubic.opts thanks!
		self.opts = opts
		self.toInstall = []
		self.log = None
		self.config = {}
		self.port = 0
		self.notification = RcubicNotification()
		self.rsm = ReleaseScriptManager(self)
		self.aisDir = ""
		self.aisOverrideDir = ""
		self.aisFilter = dict()
		self.gitDir = ""
		self.groupSelect = []
		self.signalEvent = gevent.event.Event()
		self.abortSent = False
		self.environment = ""
		self.resources = { }
		# dot's html map output is: "x,y x,y x,y"
		# but it should be: "x,y,x,y,x,y"
		# this is a regex to fix that
		self.fixCoord = re.compile(' (?=[\d]*,[\d]*)')
		self.gitHead = ""
		self.token = None
		baseConfigReq = [ "basePath", "hostListLocation", "gitRepo", "fileMode", "gerritURL", "gerritProject",
						  "environmentOptions", "specialGroups", "specialJobs",
						  "listenAddress", "listenPortRange", "jobExpireTime",
						  "smtpServer", "emailSubjectPrefix", "emailFrom", "maxEmailLogSizeKB",
						  "defaultRelease", "hijackPoint", "SSLKey", "SSLCert", "token"]
		splitOptions = ["specialGroups", "specialJobs"]

		#calculate path to xml relative to rcubic python, this will make symlinking tricky
		if(self.opts.conf == None):
			xmlpath = "%s/rcubic.xml" % sys.argv[0][0:sys.argv[0].rindex("/")]
		else:
			xmlpath = self.opts.conf

		self._readConfig(xmlpath, baseConfigReq, splitOptions=splitOptions)
		self.config["gitRepo"] = [self.config["gitRepo"]]

		self._initPaths()
		self._initGit()
		self._readConfig("%s/config.xml" %(self.releaseDir), splitOptions=splitOptions)

		self.resourceScheduler = ResourceScheduler(self.resources)

		self.rsm.specialJobs = self.config["specialJobs"]

		self._initNotification()

		if self.opts.sessionMode:
			self.log = LogToDB(":memory:")
		else:
			self.log = LogToDB(self.config["auditLog"])

		try:
			self._validate()
		except:
			self.cleanup()
			raise

		if self.opts.validate:
			self.cleanup()

	def _validate(self):
		if self._readNotificationConfig() <= 0:
			raise ConfigurationError("No notification configured. This is a bad thing")

		#TODO validate aisOverrideDir and aisDir (do they exist?)
		self._selectWhatToInstall()

		if self.rsm.countGroups(self.config["specialGroups"]) <= 0:
			raise ConfigurationError("ERROR: nothing to install")

		if not self._verifyBasePath():
			raise ConfigurationError("ERROR: basePath missmatch")

		self.rsm.expandglobs()
		self.rsm.convertcdep()
		self.rsm.inferParents()
		self.rsm.gparentCompile()

		if self.opts.environment:
			self.environment = self.opts.environment
		elif "environment" in self.config:
			self.environment = self.config["environment"]
		else:
			raise ConfigurationError("Environment not not specified.")

		self._updateGraph(updateDot=True)

		valid = self.validate()
		if valid != True:
			logging.error("Validation failure:\n%s" %(valid))
			raise ConfigurationError("Encountered Validation error. See above for cause of failure.")

		if self.environment not in self.config["environmentOptions"]:
			logging.error("environmentOptions: %s" %self.config["environmentOptions"])
			raise ConfigurationError("Invalid environment specified")

		if not self._verifyNotificationGroups():
			raise ConfigurationError("No notification configured. This is a bad thing")

	def _initNotification(self):
		self.notification.emailFrom = self.config["emailFrom"]
		self.notification.subject = self.config["emailSubjectPrefix"]
		self.notification.server = self.config["smtpServer"]
		self.notification.cc = self.config.get("cc", "")
		if self.opts.foreground:
			self.notification.disable()
		if self.config.get("notification", "True") == "False":
			self.notification.disable()

	def _initGit(self):
		#TODO: this will fail if called multiple times in session mode.
		if not self.config["fileMode"]:

			try:
				os.makedirs(self.gitDir)
			except OSError:
				pass

			if not os.access(self.gitDir, os.W_OK):
				raise FatalRuntimeError("ERROR: '%s' does not have write access." %self.gitDir)

			with open("/dev/null", "w") as devnull:
				if subprocess.call(["git","rev-parse","--is-inside-work-tree"], cwd=self.gitDir, stdout=devnull, stderr=devnull) == 0:
					#Repo already exists we just need to updated
					if self.opts.sessionMode:
						raise FatalRuntimeError("'%s' already exists. This should be impossible." %(self.gitDir))
				else:
					try:
						#repo does not exist and needs to be clone
						if subprocess.call(['git', 'clone', self.config["gitRepo"][0], "%s" %(self.gitDir)]) != 0:
							raise FatalRuntimeError("git clone failed")
					except:
						raise FatalRuntimeError("Cannot clone into directory. Is it not empty?")

				#this is a safety to roll back any changes someone's made
				subprocess.call(['git', 'reset', '--hard'], cwd=self.gitDir)

				#Fetch the remote target branch
				fetchCommand = ['git', 'fetch', self.config["gitRepo"][0]]
				if self.opts.refspec:
					fetchCommand.append(self.opts.refspec)
				elif self.opts.branch:
					fetchCommand.append("refs/heads/%s" % self.opts.branch)
				elif "gitBranch" not in self.config:
					fetchCommand.append("refs/heads/master")
				else:
					fetchCommand.append("refs/heads/%s" % self.config["gitBranch"])

				if subprocess.call(fetchCommand, cwd=self.gitDir) != 0:
					raise FatalRuntimeError("git fetch failed")

				#Checkout to fetched commit
				if subprocess.call(['git', 'checkout', 'FETCH_HEAD'], cwd=self.gitDir) != 0:
					raise FatalRuntimeError("git checkout failed 1")

				processResult = popenNonblock(["git", "rev-parse","HEAD"], cwd=self.gitDir)
				if(processResult[0] != 0):
					raise FatalRuntimeError("git head hash get failed")
				self.gitHead = processResult[1].rstrip()

				#subprocess.call(['git', 'log', '-1', '--format="%H"'], cwd=self.gitDir, stdout=githash) #todo:save hash
			logging.info("Git repo has been updated")
			return True
		else:
			# Copy the directory
			try:
				shutil.copytree(self.config["gitRepo"][0], self.gitDir)
			except:
				pass

			try:
				os.makedirs("%s/work/log" % (self.config["basePath"]))
			except OSError:
				pass

			if not os.access(self.gitDir, os.W_OK):
				raise FatalRuntimeError("ERROR: '%s' does not have write access." %self.gitDir)


	def _flattenOption(self, inList):
		outList = []
		s = re.compile("[;,\s]+")
		for subList in inList:
			outList.extend(s.split(subList))
		return outList

	def _populateAISFilter(self):
		self.aisFilter = dict()

		if self.opts.ais and self.opts.skipAis:
			logging.info("conflicting options selected skip and select ais. Will honnor only select.")

		if self.opts.ais:
			self.aisFilter["positiveFilter"] = True
			self.aisFilter["files"] = self._flattenOption(self.opts.ais)
			self.aisFilter["files"].extend(self.config["specialJobs"])
		elif self.opts.skipAis:
			self.aisFilter["positiveFilter"] = False
			self.aisFilter["files"] = self._flattenOption(self.opts.skipAis)

	def _aisHijack(self):
		for rs in self.rsm:
			if rs.group not in self.config["specialGroups"]:
				rs.hijack(self.config["hijackPoint"])

	def _selectGroups(self):
		if self.opts.group is not None:
			self.groupSelect = self._flattenOption(self.opts.group)
			self.groupSelect.extend(self.config["specialGroups"])

	def _initPaths(self):
		self.originalBasePath = self.config["basePath"]
		self.config["archivePath"] = "%s/archive/" % (self.config["basePath"])
		if self.opts.sessionMode:
			if self.groupSelect != []:
				groupDirString = self.groupSelect[0] #TODO properly implement 'group'.
			else:
				groupDirString = "all"
			self.config["basePath"] = "%s/%s_%s" %(self.config["basePath"], uuid.uuid1(), groupDirString)

		self.logDir = "%s/work/log" % self.config["basePath"]
		self.gitDir = "%s/work/git" % self.config["basePath"]
		if self.opts.release:
			self.config["defaultRelease"] = self.opts.release
		self.releaseDir = "%s/%s" % (self.gitDir, self.config["defaultRelease"])
		self.aisOverrideDir = "%s/override" % self.releaseDir
		self.aisDir = "%s/release" % self.gitDir
		self.validationDir = "%s/validation" % self.gitDir

		if "baseURL" in self.config:
			workpath = self.config["basePath"][len(self.originalBasePath):]
			self.baseURL = "%s" %self.config["baseURL"]
			try:
				self.pathURL = re.search('(?<=[^/:])/.*', self.baseURL).group(0)
			except AttributeError:
				self.pathURL = ""
			self.fullURL = "%s?prefix=%s/%s/work" %(self.baseURL, self.pathURL, workpath)
			logging.info("URL: %s" % self.fullURL)

		fileMap = { "fdotFile":"full.dot", "fpngFile":"full.png", "adotFile":"arb.dot",
					"asvgFile":"arb.svg", "pidFile":"rcubic.pid", "logFile":"rcubic.log",
					"auditLog":"rcubic.aud" , "njsonFile": "nodes.json"}
		for k, v in fileMap.iteritems():
			self.config[k] = "%s/work/%s" %(self.config["basePath"], v)


	def _readConfig(self, configFile, mustHaveConfigOptions=None, splitOptions=None):
		if mustHaveConfigOptions is None:
			mustHaveConfigOptions = []
		if splitOptions is None:
			splitOptions = []

		try:
			self.etree = etree.parse(configFile)
		except IOError:
			raise ConfigurationError("ERROR: Could not open configuration file (%s)." %(configFile))
		except etree.XMLSyntaxError as error:
			raise ConfigurationError("ERROR: failed to parse config file (%s): %s" %(configFile, error))

		#TODO save config to local var and then copy values after tweaking
		for element in self.etree.xpath("/rcubic/config/option"):
			try:
				if element.attrib["name"] == "basePath" and "basePath" in self.config:
					raise ConfigurationError("ERROR: basePath is being overriden in %s." %(configFile))
				elif element.attrib["name"] in splitOptions:
					self.config[element.attrib["name"]] = element.attrib["value"].split()
				else:
					self.config[element.attrib["name"]] = element.attrib["value"]
			except KeyError:
				self.config = {}
				raise ConfigurationError("ERROR: Element on line %i of %s is missing an attribute." %(element.sourceline, element.base))

		# Go through resources limit config
		for element in self.etree.xpath("/rcubic/resources/option"):
			try:
				resource = element.attrib["name"]
				value = int(element.attrib["value"])
				if value == -1:
					value = float('inf')
				self.resources[resource] = value
			except ValueError:
				raise ConfigurationError("ERROR: Resource on line %i of %s if not an int." % (element.sourceline, element.base))
			except:
				raise ConfigurationError("ERROR: Resource on line %i of %s is malformed." % (element.sourceline, element.base))

		for mhco in mustHaveConfigOptions:
			if mhco not in self.config:
				raise ConfigurationError("ERROR: %s is not defined in config file (%s)" %(mhco, configFile))

		#value validation does not belong in this function
		if "listenPortRange" in self.config and "listenPortRange" in mustHaveConfigOptions:
			listenPorts=[]
			try:
				for port in self.config["listenPortRange"].split('-'):
					listenPorts.append(int(port.strip()))
				if len(listenPorts) != 2:
					raise ValueError
				self.config["listenPortRange"] = ( listenPorts[0], listenPorts[1] )
			except ValueError:
				raise ConfigurationError("ERROR: port range specification error: %s" %(self.config["listenPortRange"]))

		#value validation does not belong in this function
		if "jobExpireTime" in self.config and "jobExpireTime" in mustHaveConfigOptions:
			try:
				self.config["jobExpireTime"] = int(self.config["jobExpireTime"])
			except ValueError:
				raise ConfigurationError("ERROR: jobExpireTime validation failure")

		# String to bool
		if "fileMode" in mustHaveConfigOptions:
			if self.config["fileMode"].lower() == "true":
				self.config["fileMode"] = True
			elif self.config["fileMode"].lower() == "false":
				self.config["fileMode"] = False
			else:
				raise ConfigurationError("ERROR: fileMode validation failure: expected True/False")

		return True

	def _selectWhatToInstall(self):
		self._selectGroups()
		self._populateAISFilter()
		toInstallGroups=[]

		for element in self.etree.xpath("/rcubic/release/install"):
			try:
				version = element.attrib["version"]
				group = element.attrib["group"]
			except KeyError:
				raise ConfigurationError("Element on line %i of %s is missing an attribute." %(element.sourceline, element.base))

			phase = ReleaseScript.Phase.DEFAULT
			if "phase" in element.attrib:
				phase = element.attrib["phase"].upper()
				if not phase in ReleaseScript.Phase.all:
					raise ConfigurationError("Attribute phase on line %i of %s has unrecognized value: '%s'." %(element.sourceline, element.base, phase))

			try:
				fullOverride = element.attrib["fullOverride"]
				if fullOverride.lower() == "true":
					fullOverride = True
				elif fullOverride.lower() == "false":
					fullOverride = False
				else:
					raise ConfigurationError("Element fullOverride is not (True|False) on line %i of %s." %(element.sourceline, element.base))
			except KeyError:
				fullOverride = False

			toInstall = False
			if group in self.config["specialGroups"]:
				toInstall = True
			if self.groupSelect:
				if group in self.groupSelect:
					toInstall = True
			else:
				if self.log.isNewestVersion(group, version):
					toInstall = True
				else:
					logging.info("Skipping %s a version greater than or equal %s is installed." %(group, version))

			installed = 0
			if toInstall:
				toInstallGroups.append(group)
				if not fullOverride:
					installed += self.rsm.addGroup(self.aisDir, group, version, phase, self.aisFilter)
				installed += self.rsm.addGroup(self.aisOverrideDir, group, version, phase, self.aisFilter)
				if installed <= 0:
					raise ConfigurationError("No matching install scripts found for group: %s." %(group))

		for g in self.groupSelect:
			if not g in toInstallGroups:
				raise ConfigurationError("Group %s is not in the configuration" % g)
		logging.info("Installing groups %s." % " ".join(sorted(toInstallGroups)))

		if self.aisFilter:
			self._aisHijack()

		return True

	def _readNotificationConfig(self):
		count = 0
		for product in self.etree.xpath("/rcubic/notification/product"):
			try:
				self.notification.addProductEmail(product.attrib["name"], product.attrib["email"])
			except KeyError:
				logging.error("Element on line %i of %s is missing an attribute." %(product.sourceline, product.base))
				return 0
			count += 1
		return count

	def _verifyNotificationGroups(self):
		exit = True
		for rs in self.rsm:
			for product in rs.products:
				if not self.notification.isProductConfigured(product):
					exit = False
					logging.error("'%s' references notification group '%s' which is not defined" %(rs.script, product))
		return exit

	def _verifyBasePath(self):
		for rs in self.rsm:
			if not rs.script.startswith(self.config["basePath"]):
				return False
		return True

	def reschedule(self, scriptName):
		response = self.rsm.find(scriptName)
		if not response:
			return False
		gevent.spawn(response.queue)
		return True

	def manualOverride(self, scriptName):
		response = self.rsm.find(scriptName)
		if not response:
			print("No such script")
			return False
		response.status = Status.MANUALOVERRIDE
		self.refreshStatus(response)
		response.event.set()
		return True

	def validate(self):
		errorMessages = ""

		#Validate and run validation scripts
		if self.opts.strictValidation:
			if os.path.exists(self.validationDir):
				arguments = [ self.environment, self.opts.release, " ".join(self.rsm.groups) ]
				prependRe = re.compile("^", re.M)
				for validationScript in os.listdir(self.validationDir):
					validationScript = "%s/%s" %(self.validationDir, validationScript)
					if not os.access(validationScript, os.X_OK):
						errorMessages += "\tValidation script %s is not executable\n" % (validationScript)
						continue
					with open("/dev/null", "w") as devnull:
						process = subprocess.Popen(["bash", "-n", validationScript], stdout=devnull, stderr=devnull)
					if process.wait() != 0:
						errorMessages += "\tValidation script %s is not valid bash\n" % (validationScript)
						continue
					vsl = [validationScript]
					vsl.extend(arguments)
					process = subprocess.Popen(vsl, cwd = self.releaseDir, stdout = subprocess.PIPE, stderr = subprocess.PIPE )
					if process.wait() != 0:
						stdout, stderr = process.communicate()
						if stdout or stdout:
							errorMessages += "\tValidation script %s failed:\n" % (validationScript)
						if stdout:
							errorMessages += "\t\tstdout:\n"
							errorMessages += prependRe.sub("\t\t\t", stdout.strip(), 0)
							errorMessages += "\n"
						if stderr:
							errorMessages += "\t\tstderr:\n"
							errorMessages += prependRe.sub("\t\t\t", stderr.strip(), 0)
							errorMessages += "\n"

		rsmErrorMessages = self.rsm.validate()
		if rsmErrorMessages != True:
			errorMessages += rsmErrorMessages

		if errorMessages == "":
			return True
		else:
			return errorMessages

	def _updateGraph(self, updateDot=False):
		logging.debug("Update graph called")
		try:
			meta = [
					#fullpng takes too long to render
					#(self.config["fdotFile"], self.config["fpngFile"], self.config["fhtmlFile"], False),
					(self.config["adotFile"], self.config["asvgFile"], self.config["njsonFile"], True)
				   ]
			for df, sf, jn, t in meta:
				if updateDot:
					with open(df, "w") as dotFD:
						dotFD.write(self.rsm.toDot(self.config["baseURL"], len(self.gitDir), t))
					with open(sf, "w") as svgFD:
						processResult = popenNonblock(["dot", "-Tsvg", df])
						# Regex fix the coordinate space comma issue (look at fixCoord definition)
						svgFD.write(self.fixCoord.sub(',', processResult[1]))
					if processResult[0] != 0:
						return False
				with open(jn, "w") as jsonFD:
					jsonFD.write(self.rsm.toJSON(t))

			return True
		except OSError:
			raise FatalRuntimeError("ERROR: graphviz not installed.")
			return False

	def _updateProgress(self, scriptName, version, kind, message):
		rs = self.rsm.find(scriptName)
		if not rs:
			logging.error("received message with unmatched script. (%s, %s)" %(scriptName, version))
			return False
		if rs.version != version:
			logging.error("received message with unmatched version. (%s, %s)" %(scriptName, version))
			return False
		if kind == "PROGRESS":
			if not rs.updateProgress(message):
				logging.error("received message with invalid progress message. (%s, %s, %s)" %(scriptName, version, message))
				return False
			self.signalEvent.set()
		else:
			logging.error("received message with unknown message type (%s)." %(kind))
			return False
		return True

	def refreshStatus(self, rs):
		self.signalEvent.set()

		self.log.saveStatus(rs.group, rs.version, rs.status, self.gitHead, rs.name)
		if rs.isDone() and self.rsm.isGroupSuccess(rs.group):
			self.log.saveStatus(rs.group, rs.version, rs.status, self.gitHead)
			pass

		if self.opts.sessionMode and rs.isFailed:
			self.abort()

		if rs.isFailed:
			# Get last 'maxEmailLogSizeKB' kilobytes of log for email.
			try:
				logFile=open("%s/work/log/%s.log" %((self.manager.rcubic.config["basePath"], self.name)), 'r')
				logFile.seek(0,2)
				logSize = logFile.tell()
				logFile.seek(max(-1024 * self.config['maxEmailLogSizeKB'], -logSize), 2)
				logContent = logFile.read()
			except:
				logContent="ERROR opening log file!"
			self.notification.notifyProduct(rs.products, "%s (%s) failed" %(rs.name, rs.version), logContent)
		elif rs.hasFailed and rs.isSuccess():
			self.notification.notifyProduct(rs.products, "%s (%s) recovered" %(rs.name, rs.version), "The script %s which has previously failed has now succeeded." % rs.name)

	def abort(self, signum=None, frame=None):
		#TODO: remove this and just call the RSM one
		#signum and frame are needed as they are passed up from threading class.
		if self.abortSent:
			logging.error("Abort already sent to all jobs.")
			logging.debug("jobs: %s" % self.rsm)
			return
		else:
			self.abortSent = True

		logging.info("Aborting all jobs. Please be patient.")
		self.rsm.abortJobs()

	def processEvents(self):
		#We sleep here to give socket server some time to init
		#TODO: use event set in communicator to let us know that its ready
		gevent.sleep(1)

		expireTime = time.time() + 3600 * self.config["jobExpireTime"]
		while self.communicator.started():
				self.signalEvent.wait(10.0)
				if self.signalEvent.is_set():
					self.signalEvent.clear()
					self._updateGraph()
					self.notification.processQueue()
				if self.opts.sessionMode or self.abortSent:
					if self.rsm.isDone():
						break
				else:
					if self.rsm.isSuccess():
						break
				if time.time() > expireTime:
					logging.error("Tired of waiting for jobs to exit. Aborting.")
					self.abort()
					break
		self.communicator.stop()

	def cleanup(self):
		try:
			if(not self.opts.sessionMode):
				uid = uuid.uuid1()
				archiveDir = "%s/%s" % (self.config["archivePath"], uid)
				os.makedirs(archiveDir)
				files = [ self.config['adotFile'], self.config['asvgFile'], self.config['njsonFile'] ]
				if not self.opts.foreground and not self.opts.validate:
					files.append(self.config['logFile'])
				for f in files:
					shutil.copy(f, archiveDir)
				if(not self.opts.validate):
					shutil.copytree("%s/%s" % (self.config["basePath"], "work/log"), "%s/%s" % (archiveDir,"log"))
				logging.info("Copied files to: %s" % (archiveDir))

				archiveURL = "%s?prefix=%s/archive/%s" %(self.baseURL, self.pathURL, uid)
				logging.info("Job archive available at: %s" % (archiveURL))
		except:
			logging.error("Something went wrong while trying to copy files to archive: %s" % (str(sys.exc_info())))

		if self.opts.sessionMode:
			try:
				shutil.rmtree("%s/%s" % (self.config["basePath"], "work/git"))
				logging.info("Removed git directory from session folder.")
			except:
				logging.error("Something went wrong when trying to remove git directory from session folder: %s" % (str(sys.exc_info())))


	def run(self):
		time.sleep(1) #Sleep to let stdout get re-assigned on daemonization fork

		#In session mode logging to DB makes little sense as it will never be re-used. Instead we just log to memory.
		if self.opts.sessionMode:
			self.log = LogToDB(":memory:")
		else:
			self.log = LogToDB(self.config["auditLog"])

		#Cleanup and setup log directory.
		if not self.opts.sessionMode:
			try:
				shutil.rmtree(self.logDir)
			except:
				logging.exception("Failed to clean up log directory")
		try:
			os.makedirs(self.logDir)
		except OSError:
			pass

		self._updateGraph()
		if self.config["SSLKey"] == "" or self.config["SSLCert"] == "":
			self.config["SSLKey"] = None
			self.config["SSLCert"] = None
		if self.config["token"] == "":
			self.config["token"] = None

		self.communicator = RESTCommunicator(self, bind=self.config["listenAddress"], portRange=self.config["listenPortRange"], SSLKey=self.config["SSLKey"], SSLCert=self.config["SSLCert"], token=self.config["token"])
		rse = self.rsm.queueJobs() #release script event

		jobs = [gevent.spawn(rsei) for rsei in rse]
		jobs.extend([gevent.spawn(self.processEvents)])
		# Starts non-blocking so we can get port
		self.communicator.start(block=False)
		logging.info("Server started at %s:%s" % (self.communicator.bind, self.communicator.port))
		self.token = self.communicator.token
		self.port = self.communicator.port
		gevent.joinall(jobs)
		time.sleep(5)
		self._updateGraph(updateDot=True)
		self.notification.processQueue()

		self.cleanup()

		if not self.rsm.isDone():
			logging.error("exited with orphaned jobs")
			return False
		return self.rsm.isSuccess()

class RcubicDaemon(Daemon):
	def setRcubic(self,rcubic):
		self.rcubic = rcubic
	def run(self):
		self.rcubic.run()

def _setupLogging():
	dpp12_time = '%Y-%m-%d %H:%M:%S' + str.format('{0:+06.2f}', float(time.altzone) / 3600).replace(".", "")
	log_format = logging.Formatter('[%(asctime)s] | %(filename)s | %(process)d | %(levelname)s | %(message)s', datefmt=dpp12_time)
	handler = logging.StreamHandler()
	handler.setFormatter(log_format)
	logger = logging.getLogger('')
	logger.setLevel(logging.INFO)
	#logger.setLevel(logging.DEBUG)
	logger.addHandler(handler)

if __name__ == "__main__":
	_setupLogging()
	argParser = argparse.ArgumentParser(description='Rcubic does stuff! Important stuff!')
	argParser.add_argument('-r', dest='release', metavar='release_directory', required=False, help='Release. Number.')
	argParser.add_argument('-g', dest='group', metavar='group', action='append',
							help='Select Group to run. Can be specified multiple times for multiple groups.')
	argParser.add_argument('-v', dest='validate', action='store_const', const=True, default=False, help='Validate configuration.')
	argParser.add_argument('-V', '--extval', '--strictValidation', dest='strictValidation', action='store_const', const=True, default=False, help='Strict validation configuration. Run validation scripts.')
	argParser.add_argument('-f', dest='foreground', action='store_const', const=True, default=False,  help='Run in foreground (debug) mode.')
	argParser.add_argument('-s', dest='sessionMode', action='store_const', const=True, default=False,  help='Run in Session mode.')
	argParser.add_argument('-a', dest='ais', metavar='ais_list', action='append', default=None,
							help='Select a single AIS to run. Can be specified multiple times for multiple AIS. Do not use with -i.')
	argParser.add_argument('-A', dest='skipAis', metavar='ais_list', action='append', default=None,
							help='Select an AIS to skip. Can be specified multiple times for multiple AIS. Do not use with -a.')
	argParser.add_argument('--refspec', dest='refspec', metavar='refspec', default=None,  help='refspec to fetch from, sets branch to FETCH_HEAD.')
	argParser.add_argument('-b', dest='branch', metavar='branch', default=None, help='branch to checkout defaults to master unless --refspec is specified')
	argParser.add_argument('-e', dest='environment', metavar='environmet', required=False, help='Environment options.')
	argParser.add_argument('-c','--config', dest='conf', default=None, help='path to rcubic.xml config file. Default RCubic.run directory')
	opts = argParser.parse_args()

	try:
		rcubic = Rcubic(opts)
	except ConfigurationError as ce:
		logging.error(ce)
		logging.error("Encountered configuration error. See above for cause of failure.")
		sys.exit(2)

	if opts.validate:
		logging.info("Passed Validation!") #This won't be reached if errors are found.
		sys.exit(0)

	signal.signal(signal.SIGTERM, rcubic.abort)
	signal.signal(signal.SIGINT, rcubic.abort)

	if opts.foreground:
		if rcubic.run():
			sys.exit(0)
		else:
			sys.exit(1)
	else:
		rcubicd = RcubicDaemon(rcubic.config["pidFile"], stdout=rcubic.config["logFile"], stderr=rcubic.config["logFile"])
		rcubicd.setRcubic(rcubic)
		rcubicd.start()
